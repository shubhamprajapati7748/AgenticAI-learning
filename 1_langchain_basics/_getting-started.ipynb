{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['LANGSMITH_API_KEY'] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ['LANGSMITH_PROJECT'] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ['LANGSMITH_TRACING'] = os.getenv(\"LANGSMITH_TRACING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000023CFF3144A0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000023CFBA64B00>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=\"Gemma2-9b-It\")\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI Agents are software programs that can **act autonomously** to achieve specific goals. They are designed to perceive their environment, make decisions, and take actions to interact with it, all without direct human intervention. \\n\\nThink of them like virtual assistants, but with more capabilities. \\n\\nHere\\'s a breakdown:\\n\\n**Key Characteristics:**\\n\\n* **Autonomy:** AI agents can operate independently, making decisions and taking actions based on their programming and the information they gather.\\n* **Goal-Oriented:** They are designed to accomplish specific tasks or objectives.\\n* **Perception:** They can sense and interpret their environment through various means, such as sensors, cameras, or data feeds.\\n* **Decision-Making:** They use algorithms and learned patterns to analyze information and make choices about their actions.\\n* **Action:** They can interact with their environment by performing tasks, manipulating objects, or sending messages.\\n\\n**Types of AI Agents:**\\n\\n* **Simple Reflex Agents:** React directly to their environment based on pre-programmed rules.\\n* **Model-Based Reflex Agents:** Build a model of the world and use it to make decisions.\\n* **Goal-Based Agents:**  Have a set of goals and plan actions to achieve them.\\n* **Utility-Based Agents:** Choose actions that maximize a measure of \"utility\" or satisfaction.\\n* **Learning Agents:** Can learn and improve their performance over time through experience.\\n\\n**Examples:**\\n\\n* **Chatbots:** Provide conversational interactions with users.\\n* **Self-Driving Cars:** Navigate roads and make driving decisions.\\n* **Recommendation Systems:** Suggest products or content based on user preferences.\\n* **Game AI:** Control non-player characters in video games.\\n* **Fraud Detection Systems:** Identify suspicious transactions.\\n\\n\\nAI agents are a powerful tool with wide-ranging applications. As AI technology advances, we can expect to see even more sophisticated and capable AI agents in the future.\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 400, 'prompt_tokens': 14, 'total_tokens': 414, 'completion_time': 0.727272727, 'prompt_time': 8.284e-05, 'queue_time': 0.023613889, 'total_time': 0.727355567}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-74429876-ec90-4635-a318-29828c3600b1-0', usage_metadata={'input_tokens': 14, 'output_tokens': 400, 'total_tokens': 414})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## input and get response from LLM \n",
    "result = llm.invoke(\"What is AI Agents?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI engineer. Provide me answers based on questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert AI engineer. Provide me answers based on questions\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Chain on workflows -> First go to prompt and then llm\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"##  LangChain: Your AI Application Framework \\n\\nAs an AI engineer, I see LangChain as a powerful tool for building applications using large language models (LLMs). Think of it as a framework, a set of tools and building blocks that makes it easier to integrate LLMs into your projects.\\n\\nHere's a breakdown of what makes LangChain so special:\\n\\n**1. Bridging the Gap:**\\n\\n* **LLMs are great at understanding and generating text,** but they lack the ability to interact with the world directly. LangChain acts as the bridge, connecting LLMs to external data sources, APIs, and other tools.\\n\\n**2. Modular and Customizable:**\\n\\n* LangChain is built on a modular architecture, allowing you to choose the components that best suit your needs. \\n* Need to query a database? LangChain has you covered. Want to chain together multiple LLMs for complex tasks?\\n\\nNo problem!\\n\\n**3. Key Components:**\\n\\n* **Chains:** The heart of LangChain, chains define sequences of actions involving LLMs and other tools. Imagine a chain that takes a user query, searches a database for relevant information, summarizes the results, and presents them to the user in a conversational manner.\\n* **Agents:**  Agents are more autonomous, capable of making decisions and taking actions based on LLM outputs. Think of a customer service agent powered by LangChain that can answer questions, resolve issues, and even suggest products based on user needs.\\n* **Memory:** LangChain provides different memory mechanisms to allow LLMs to retain context across multiple interactions, enabling more natural and meaningful conversations.\\n\\n**4. Examples in Action:**\\n\\n* **Chatbots:**  Build sophisticated chatbots that can answer questions, provide personalized recommendations, and even engage in creative writing.\\n* **Code Assistants:**  Develop AI-powered tools that help developers write, debug, and understand code.\\n* **Data Analysis:**  Automate data analysis tasks by leveraging LLMs to extract insights from unstructured text data.\\n\\n**Getting Started:**\\n\\nLangChain is open-source and well-documented, making it accessible to developers of all levels. \\n\\nCheck out their website ([https://python.langchain.com/](https://python.langchain.com/)) for tutorials, examples, and the latest updates.\\n\\n**In essence, LangChain empowers you to go beyond simple text generation and unlock the true potential of LLMs for building innovative and impactful applications.**\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 510, 'prompt_tokens': 27, 'total_tokens': 537, 'completion_time': 0.927272727, 'prompt_time': 0.000322179, 'queue_time': 0.020354211, 'total_time': 0.927594906}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c21ab6d4-8940-47d2-ade8-9f458865efad-0', usage_metadata={'input_tokens': 27, 'output_tokens': 510, 'total_tokens': 537})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\" : \"Tell me about langchain\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"##  LangChain: Your AI Application Framework \\n\\nAs an AI engineer, I see LangChain as a powerful tool for building applications using large language models (LLMs). Think of it as a framework, a set of tools and building blocks that makes it easier to integrate LLMs into your projects.\\n\\nHere's a breakdown of what makes LangChain so special:\\n\\n**1. Bridging the Gap:**\\n\\n* **LLMs are great at understanding and generating text,** but they lack the ability to interact with the world directly. LangChain acts as the bridge, connecting LLMs to external data sources, APIs, and other tools.\\n\\n**2. Modular and Customizable:**\\n\\n* LangChain is built on a modular architecture, allowing you to choose the components that best suit your needs. \\n* Need to query a database? LangChain has you covered. Want to chain together multiple LLMs for complex tasks?\\n\\nNo problem!\\n\\n**3. Key Components:**\\n\\n* **Chains:** The heart of LangChain, chains define sequences of actions involving LLMs and other tools. Imagine a chain that takes a user query, searches a database for relevant information, summarizes the results, and presents them to the user in a conversational manner.\\n* **Agents:**  Agents are more autonomous, capable of making decisions and taking actions based on LLM outputs. Think of a customer service agent powered by LangChain that can answer questions, resolve issues, and even suggest products based on user needs.\\n* **Memory:** LangChain provides different memory mechanisms to allow LLMs to retain context across multiple interactions, enabling more natural and meaningful conversations.\\n\\n**4. Examples in Action:**\\n\\n* **Chatbots:**  Build sophisticated chatbots that can answer questions, provide personalized recommendations, and even engage in creative writing.\\n* **Code Assistants:**  Develop AI-powered tools that help developers write, debug, and understand code.\\n* **Data Analysis:**  Automate data analysis tasks by leveraging LLMs to extract insights from unstructured text data.\\n\\n**Getting Started:**\\n\\nLangChain is open-source and well-documented, making it accessible to developers of all levels. \\n\\nCheck out their website ([https://python.langchain.com/](https://python.langchain.com/)) for tutorials, examples, and the latest updates.\\n\\n**In essence, LangChain empowers you to go beyond simple text generation and unlock the true potential of LLMs for building innovative and impactful applications.**\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parser \n",
    "- To make output in the fix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"##  LangChain: Your Guide to Building Powerful Applications with Language Models \\n\\nAs an AI engineer, I see LangChain as a game-changer in the world of AI development.  It's not just another library; it's a **framework** designed to simplify the process of building applications powered by large language models (LLMs). \\n\\nThink of LangChain as the **Lego blocks of LLM applications**. It provides you with:\\n\\n**1. Building Blocks:**\\n\\n- **Models:**  Easily integrate various LLMs like OpenAI's GPT, Cohere, HuggingFace models, and more.\\n- **Prompts:** Craft and manage sophisticated prompts to elicit desired responses from LLMs.\\n- **Chains:**  Connect multiple LLMs and tools together to create complex workflows.\\n- **Memory:**  Give your applications context and remember past interactions for more natural conversations.\\n- **Agents:**  Build autonomous agents that can interact with the world through APIs and other tools.\\n\\n**2. Abstraction:**\\n\\nLangChain abstracts away the complexities of LLMs, allowing you to focus on the **logic and functionality** of your application.\\n\\n**3. Flexibility:**\\n\\nIt's highly modular and customizable, letting you **tailor your solutions** to specific needs.\\n\\n**Here are some key benefits of using LangChain:**\\n\\n- **Rapid Prototyping:** Quickly build and test LLM-powered applications without getting bogged down in technical details.\\n- **Improved Efficiency:**  Reuse and combine existing components, saving time and effort.\\n- **Enhanced Capabilities:**  Access a wide range of tools and integrations to extend the functionality of your applications.\\n- **Scalability:**  Build applications that can handle large volumes of requests and complex tasks.\\n\\n**LangChain is ideal for building a variety of applications, including:**\\n\\n- **Chatbots and Conversational Agents:**  Create engaging and informative chatbots that can assist users with tasks and provide information.\\n- **Question Answering Systems:**  Develop systems that can accurately answer questions based on a given context or knowledge base.\\n- **Text Summarization and Analysis:**  Automate the summarization of large amounts of text and extract key insights.\\n- **Code Generation and Assistance:**  Leverage LLMs to generate code snippets and assist developers with coding tasks.\\n- **Data Extraction and Processing:**  Extract valuable information from unstructured data sources like documents and emails.\\n\\n**Want to learn more?**\\n\\n- **Official Documentation:** [https://python.langchain.com/](https://python.langchain.com/)\\n- **GitHub Repository:** [https://github.com/langchain-org/langchain](https://github.com/langchain-org/langchain)\\n- **Community Forum:** [https://discord.gg/langchain](https://discord.gg/langchain)\\n\\n\\nLet me know if you have any more questions about LangChain or its capabilities. I'm here to help you explore the exciting world of LLM applications!\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser \n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\" : \"Tell me about langchain\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PromptTemplate - System and User message seperatly\n",
    "from langchain_core.prompts import PromptTemplate \n",
    "from langchain_core.output_parsers import JsonOutputParser \n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the uer query. \\n {format_instruction} \\n {user_query} \\n\",\n",
    "    input_variables= [\"user_query\"],\n",
    "    partial_variables={\"format_instruction\" : output_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"user_query\" : \"Tell me about LangSmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangSmith',\n",
       " 'description': 'LangSmith is an open-source platform designed to simplify the process of fine-tuning large language models (LLMs).',\n",
       " 'features': ['User-friendly interface for interacting with LLMs',\n",
       "  'Integrated tools for data preparation and model training',\n",
       "  'Support for various popular LLMs, including Llama 2',\n",
       "  'Collaborative features for joint development and fine-tuning',\n",
       "  'Focus on accessibility and ease of use for both beginners and experts'],\n",
       " 'benefits': ['Accelerated development of customized LLMs',\n",
       "  'Reduced technical barriers to LLM fine-tuning',\n",
       "  'Enhanced control and customization over LLM behavior',\n",
       "  'Community-driven innovation and shared knowledge',\n",
       "  'Cost-effective alternative to proprietary LLM platforms'],\n",
       " 'website': 'https://github.com/microsoft/LangSmith'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llnewvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
