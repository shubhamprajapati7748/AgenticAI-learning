{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Flow\n",
    "\n",
    "Load Data -> Docs -> Divide docs into chunks -> Convert chunks into vector (Vector Embedding) -> Store vectors into VectorStore\n",
    "\n",
    "1. Data Loader - Loading the data\n",
    "2. Data Tranformation -> Divide the loaded data into chunks\n",
    "3. Data Embedding -> Convert chunks data into vectors \n",
    "4. Vector Store -> Store the vectors into DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x11435b830>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WebBaseLoader(\"https://python.langchain.com/docs/integrations/document_loaders/web_base/\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nWebBaseLoader | ü¶úÔ∏èüîó LangChain\\n\\n\\n\\n\\n\\n\\nSkip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepSeekDeepSparseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AIGeopandasGitGitBookGitHubGitLabGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK√πzuLabel StudiolakeFSLanceDBLangChain Decorators ‚ú®LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWikiDumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot√∂rheadMyScaleNAVERNeo4jNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesPandasPaymanAIPebbloPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salute DevicesSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterxAIXataXorbits Inference (Xinference)YahooYandexYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsChat modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflare Workers AICohereCoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFireworksChatFriendliGigaChatGoodfireGoogle AIGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLLM RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSambaNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM ChatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCohere RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalMilvus Hybrid SearchNanoPQ (Product Quantization)needleNimbleOutlinePinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSingleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/ToolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenWeatherMapOracle AI Vector Search: Generate SummaryPandas DataframePassio NutritionAIPaymanAIPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTavily SearchTiloresTwilioUpstageWikidataWikipediaWolfram AlphaYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modePandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdLoaderPyMuPDFLoaderPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdIntel\\'s Visual Data Management System (VDMS)VearchVectaraVespaviking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel¬Æ Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersWebBaseLoaderOn this pageWebBaseLoader\\nThis covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.\\nIf you don\\'t want to worry about website crawling, bypassing JS-blocking sites, and data cleaning, consider using FireCrawlLoader or the faster option SpiderLoader.\\nOverview\\u200b\\nIntegration details\\u200b\\n\\nTODO: Fill in table features.\\nTODO: Remove JS support link if not relevant, otherwise ensure link is correct.\\nTODO: Make sure API reference links are correct.\\n\\nClassPackageLocalSerializableJS supportWebBaseLoaderlangchain_community‚úÖ‚ùå‚ùå\\nLoader features\\u200b\\nSourceDocument Lazy LoadingNative Async SupportWebBaseLoader‚úÖ‚úÖ\\nSetup\\u200b\\nCredentials\\u200b\\nWebBaseLoader does not require any credentials.\\nInstallation\\u200b\\nTo use the WebBaseLoader you first need to install the langchain-community python package.\\n%pip install -qU langchain_community beautifulsoup4\\nInitialization\\u200b\\nNow we can instantiate our model object and load documents:\\nfrom langchain_community.document_loaders import WebBaseLoaderloader = WebBaseLoader(\"https://www.example.com/\")API Reference:WebBaseLoader\\nTo bypass SSL verification errors during fetching, you can set the \"verify\" option:\\nloader.requests_kwargs = {\\'verify\\':False}\\nInitialization with multiple pages\\u200b\\nYou can also pass in a list of pages to load from.\\nloader_multiple_pages = WebBaseLoader(    [\"https://www.example.com/\", \"https://google.com\"])\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDocument(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\')\\nprint(docs[0].metadata)\\n{\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}\\nLoad multiple urls concurrently\\u200b\\nYou can speed up the scraping process by scraping and parsing multiple urls concurrently.\\nThere are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren\\'t concerned about being a good citizen, or you control the server you are scraping and don\\'t care about load, you can change the requests_per_second parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!\\n%pip install -qU  nest_asyncio# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()\\nNote: you may need to restart the kernel to use updated packages.\\nloader = WebBaseLoader([\"https://www.example.com/\", \"https://google.com\"])loader.requests_per_second = 1docs = loader.aload()docs\\nFetching pages: 100%|###########################################################################| 2/2 [00:00<00:00,  8.28it/s]\\n[Document(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\'), Document(metadata={\\'source\\': \\'https://google.com\\', \\'title\\': \\'Google\\', \\'description\\': \"Search the world\\'s information, including webpages, images, videos and more. Google has many special features to help you find exactly what you\\'re looking for.\", \\'language\\': \\'en\\'}, page_content=\\'GoogleSearch Images Maps Play YouTube News Gmail Drive More ¬ªWeb History | Settings | Sign in\\\\xa0Advanced search5 ways Gemini can help during the HolidaysAdvertisingBusiness SolutionsAbout Google¬© 2024 - Privacy - Terms  \\')]\\nLoading a xml file, or using a different BeautifulSoup parser\\u200b\\nYou can also look at SitemapLoader for an example of how to load a sitemap file, which is an example of using this feature.\\nloader = WebBaseLoader(    \"https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\")loader.default_parser = \"xml\"docs = loader.load()docs\\n[Document(metadata={\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}, page_content=\\'\\\\n\\\\n10\\\\nEnergy\\\\n3\\\\n2018-01-01\\\\n2018-01-01\\\\nfalse\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n√Ç¬ß 431.86\\\\nSection √Ç¬ß 431.86\\\\n\\\\nEnergy\\\\nDEPARTMENT OF ENERGY\\\\nENERGY CONSERVATION\\\\nENERGY EFFICIENCY PROGRAM FOR CERTAIN COMMERCIAL AND INDUSTRIAL EQUIPMENT\\\\nCommercial Packaged Boilers\\\\nTest Procedures\\\\n\\\\n\\\\n\\\\n\\\\n¬ß\\\\u2009431.86\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n(a) Scope. This section provides test procedures, pursuant to the Energy Policy and Conservation Act (EPCA), as amended, which must be followed for measuring the combustion efficiency and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by conducting the appropriate test procedure(s) indicated in Table 1 of this section.\\\\n\\\\nTable 1‚ÄîTest Requirements for Commercial Packaged Boiler Equipment Classes\\\\n\\\\nEquipment category\\\\nSubcategory\\\\nCertified rated inputBtu/h\\\\n\\\\nStandards efficiency metric(¬ß\\\\u2009431.87)\\\\n\\\\nTest procedure(corresponding to\\\\nstandards efficiency\\\\nmetric required\\\\nby ¬ß\\\\u2009431.87)\\\\n\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n>2,500,000 and ‚â§5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3 with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\n>2,500,000 and ‚â§5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3. with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\n*\\\\u2009Equipment classes for commercial packaged boilers as of July 22, 2009 (74 FR 36355) distinguish between gas-fired natural draft and all other gas-fired (except natural draft).\\\\n\\\\n(c) Field Tests. The field test provisions of appendix A may be used only to test a unit of commercial packaged boiler with rated input greater than 5,000,000 Btu/h.\\\\n[81 FR 89305, Dec. 9, 2016]\\\\n\\\\n\\\\nEnergy Efficiency Standards\\\\n\\\\n\\')]\\nLazy Load\\u200b\\nYou can use lazy loading to only load one page at a time in order to minimize memory requirements.\\npages = []for doc in loader.lazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\n10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}\\nAsync\\u200b\\npages = []async for doc in loader.alazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\nFetching pages: 100%|###########################################################################| 1/1 [00:00<00:00, 10.51it/s]``````output10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{\\'source\\': \\'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\\'}\\nUsing proxies\\u200b\\nSometimes you might need to use proxies to get around IP blocks. You can pass in a dictionary of proxies to the loader (and requests underneath) to use them.\\nloader = WebBaseLoader(    \"https://www.walmart.com/search?q=parrots\",    proxies={        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",    },)docs = loader.load()\\nAPI reference\\u200b\\nFor detailed documentation of all WebBaseLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\\nRelated\\u200b\\n\\nDocument loader conceptual guide\\nDocument loader how-to guides\\nEdit this pageWas this page helpful?PreviousWeatherNextWhatsApp ChatOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationInitialization with multiple pagesLoadLoad multiple urls concurrentlyLoading a xml file, or using a different BeautifulSoup parserLazy LoadAsyncUsing proxiesAPI referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation\n",
    "Text -> Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='WebBaseLoader | ü¶úÔ∏èüîó LangChain'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Skip to main contentJoin us at  Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchProvidersAnthropicAWSGoogleHugging FaceMicrosoftOpenAIMoreProvidersAcreomActiveloop Deep LakeAerospikeAI21 LabsAimAINetworkAirbyteAirtableAlchemyAleph AlphaAlibaba CloudAnalyticDBAnnoyAnthropicAnyscaleApache Software FoundationApache DorisApifyAppleArangoDBArceeArcGISArgillaArizeArthurArxivAscendAskNewsAssemblyAIAstra DBAtlasAwaDBAWSAZLyricsBAAIBagelBagelDBBaichuanBaiduBananaBasetenBeamBeautiful SoupBibTeXBiliBiliBittensorBlackboardbookend.aiBoxBrave SearchBreebs (Open Knowledge)BrowserbaseBrowserlessByteDanceCassandraCerebrasCerebriumAIChaindeskChromaClarifaiClearMLClickHouseClickUpCloudflareClovaCnosDBCogniSwitchCohereCollege ConfidentialCometConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='ConfidentialCometConfident AIConfluenceConneryContextCouchbaseCozeCrateDBC TransformersCTranslate2CubeDappierDashVectorDatabricksDatadog TracingDatadog LogsDataForSEODataheraldDedocDeepInfraDeepSeekDeepSparseDiffbotDingoDBDiscordDocArrayDoclingDoctranDocugamiDocusaurusDriaDropboxDSPyDuckDBDuckDuckGo SearchE2BEden AIElasticsearchElevenLabsEmbedchainEpsillaEtherscanEverly AIEverNoteExaFacebook - MetaFalkorDBFaunaFiddlerFigmaFireCrawlFireworks AIFlyteFMP Data (Financial Data Prep)Forefront AIFriendli AIGeopandasGitGitBookGitHubGitLabGoldenGoodfireGoogleSerper - Google Search APIGooseAIGPT4AllGradientGraphsignalGrobidGroqGutenbergHacker NewsHazy ResearchHeliconeHologresHTML to textHuaweiHugging FaceHyperbrowserIBMIEIT SystemsiFixitiFlytekIMSDbInfinispan VSInfinityInfinoIntelIuguJaguarJavelin AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK√πzuLabel StudiolakeFSLanceDBLangChain Decorators ‚ú®LangFair: Use-Case Level LLM Bias and Fairness'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='AI GatewayJenkinsJina AIJohnsnowlabsJoplinKDB.AIKineticaKoboldAIKonkoKoNLPYK√πzuLabel StudiolakeFSLanceDBLangChain Decorators ‚ú®LangFair: Use-Case Level LLM Bias and Fairness AssessmentsLanternLindormLinkupLiteLLMLlamaIndexLlama.cppLlamaEdgellamafileLLMonitorLocalAILog10MariTalkMarqoMediaWikiDumpMeilisearchMemcachedMetalMicrosoftMilvusMindsDBMinimaxMistralAIMLflow AI Gateway for LLMsMLflowMLXModalModelScopeModern TreasuryMomentoMongoDBMongoDB AtlasMotherduckMot√∂rheadMyScaleNAVERNeo4jNimbleNLPCloudNomicNotion DBNucliaNVIDIAObsidianOceanBaseOracle Cloud Infrastructure (OCI)OctoAIOllamaOntotext GraphDBOpenAIOpenLLMOpenSearchOpenWeatherMapOracleAI Vector SearchOutlineOutlinesPandasPaymanAIPebbloPerplexityPetalsPostgres EmbeddingPGVectorPineconePipelineAIPipeshiftPortkeyPredibasePrediction GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salute'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='GuardPremAIPromptLayerPsychicPubMedPullMd LoaderPygmalionAIQdrantRAGatouillerank_bm25Ray ServeRebuffRedditRedisRemembrallReplicateRoamSema4 (fka Robocorp)RocksetRunhouseRWKV-4Salute DevicesSambaNovaSAPScrapeGraph AISearchApiSearxNG Search APISemaDBSerpAPIShale ProtocolSingleStoreDBscikit-learnSlackSnowflakespaCySparkSparkLLMSpreedlySQLiteStack ExchangeStarRocksStochasticAIStreamlitStripeSupabase (Postgres)NebulaTairTelegramTencentTensorFlow DatasetsTiDBTigerGraphTigrisTiloresTogether AI2MarkdownTranswarpTrelloTrubricsTruLensTwitterTypesenseUnstructuredUpstageupstashUpTrainUSearchVDMSVearchVectaraVespavliteVoyageAIWeights & BiasesWeights & Biases tracingWeights & Biases trackingWeatherWeaviateWhatsAppWhyLabsWikipediaWolfram AlphaWriterxAIXataXorbits Inference (Xinference)YahooYandexYeager.aiYellowbrick01.AIYouYouTubeZepZhipu AIZillizComponentsChat modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzure OpenAIAzure ML'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='AIZillizComponentsChat modelsChat modelsAI21 LabsAlibaba Cloud PAI EASAnthropic[Deprecated] Experimental Anthropic Tools WrapperAnyscaleAzure OpenAIAzure ML EndpointBaichuan ChatBaidu QianfanAWS BedrockCerebrasCloudflare Workers AICohereCoze ChatDappier AIDatabricksDeepInfraDeepSeekEden AIErnie Bot ChatEverlyAIFireworksChatFriendliGigaChatGoodfireGoogle AIGoogle Cloud Vertex AIGPTRouterGroqChatHuggingFaceIBM watsonx.aiJinaChatKineticaKonkoLiteLLMLiteLLM RouterLlama 2 ChatLlama APILlamaEdgeLlama.cppmaritalkMiniMaxMistralAIMLXModelScopeMoonshotNaverNVIDIA AI EndpointsChatOCIModelDeploymentOCIGenAIChatOctoAIOllamaOpenAIOutlinesPerplexityPipeshiftChatPredictionGuardPremAIPromptLayer ChatOpenAIRekaSambaNovaCloudSambaStudioSnowflake CortexsolarSparkLLM ChatNebula (Symbl.ai)Tencent HunyuanTogetherTongyi QwenUpstagevLLM ChatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='QwenUpstagevLLM ChatVolc Enging MaasWriterxAIYandexGPTChatYIYuan2.0ZHIPU AIRetrieversRetrieversActiveloop Deep MemoryAmazon KendraArceeArxivAskNewsAzure AI SearchBedrock (Knowledge Bases)BM25BoxBREEBS (Open Knowledge)ChaindeskChatGPT pluginCohere rerankerCohere RAGDappierDocArrayDriaElasticSearch BM25ElasticsearchEmbedchainFlashRank rerankerFleet AI ContextGoogle DriveGoogle Vertex AI SearchIBM watsonx.aiJaguarDB Vector DatabaseKay.aiKinetica Vectorstore based RetrieverkNNLinkupSearchRetrieverLLMLingua Document CompressorLOTR (Merger Retriever)MetalMilvus Hybrid SearchNanoPQ (Product Quantization)needleNimbleOutlinePinecone Hybrid SearchPubMedQdrant Sparse VectorRAGatouilleRePhraseQueryRememberizerSEC filingSelf-querying retrieversSingleStoreDBSVMTavilySearchAPITF-IDF**NeuralDB**VespaWikipediaYou.comZep CloudZep Open SourceZilliz Cloud PipelineTools/ToolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='CloudZep Open SourceZilliz Cloud PipelineTools/ToolkitsToolsAINetwork ToolkitAlpha VantageAmadeus ToolkitArXivAskNewsAWS LambdaAzure AI Services ToolkitAzure Cognitive Services ToolkitAzure Container Apps dynamic sessionsShell (bash)Bearly Code InterpreterBing SearchBrave SearchCassandra Database ToolkitCDPChatGPT PluginsClickUp ToolkitCogniswitch ToolkitConnery Toolkit and ToolsDall-E Image GeneratorDappierDatabricks Unity Catalog (UC)DataForSEODataheraldDuckDuckGo SearchE2B Data AnalysisEden AIEleven Labs Text2SpeechExa SearchFile SystemFinancialDatasets ToolkitFMP DataGithub ToolkitGitlab ToolkitGmail ToolkitGolden QueryGoogle BooksGoogle Cloud Text-to-SpeechGoogle DriveGoogle FinanceGoogle ImagenGoogle JobsGoogle LensGoogle PlacesGoogle ScholarGoogle SearchGoogle SerperGoogle TrendsGradioGraphQLHuggingFace Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Hub ToolsHuman as a toolIFTTT WebHooksInfobipIonic Shopping ToolJenkinsJina SearchJira ToolkitJSON ToolkitLemon AgentLinkupSearchToolMemorizeMojeek SearchMultiOn ToolkitNASA ToolkitNuclia UnderstandingNVIDIA Riva: ASR and TTSOffice365 ToolkitOpenAPI ToolkitNatural Language API ToolkitsOpenWeatherMapOracle AI Vector Search: Generate SummaryPandas DataframePassio NutritionAIPaymanAIPlayWright Browser ToolkitPolygon IO Toolkit and ToolsPowerBI ToolkitPubMedPython REPLReddit SearchRequests ToolkitRiza Code InterpreterRobocorp ToolkitSceneXplainScrapeGraphSearchApiSearxNG SearchSemantic Scholar API ToolSerpAPISlack ToolkitSpark SQL ToolkitSQLDatabase ToolkitStackExchangeSteam ToolkitStripeTavily SearchTiloresTwilioUpstageWikidataWikipediaWolfram AlphaYahoo Finance NewsYou.com SearchYouTubeZapier Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Natural Language ActionsZenGuard AIDocument loadersDocument loadersacreomAirbyteLoaderAirbyte CDK (Deprecated)Airbyte Gong (Deprecated)Airbyte Hubspot (Deprecated)Airbyte JSON (Deprecated)Airbyte Salesforce (Deprecated)Airbyte Shopify (Deprecated)Airbyte Stripe (Deprecated)Airbyte Typeform (Deprecated)Airbyte Zendesk Support (Deprecated)AirtableAlibaba Cloud MaxComputeAmazon TextractApify DatasetArcGISArxivLoaderAssemblyAI Audio TranscriptsAstraDBAsync ChromiumAsyncHtmlAthenaAWS S3 DirectoryAWS S3 FileAZLyricsAzure AI DataAzure Blob Storage ContainerAzure Blob Storage FileAzure AI Document IntelligenceBibTeXBiliBiliBlackboardBlockchainBoxBrave SearchBrowserbaseBrowserlessBSHTMLLoaderCassandraChatGPT DataCollege ConfidentialConcurrent LoaderConfluenceCoNLL-UCopy PasteCouchbaseCSVCube Semantic LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='LayerDatadog LogsDedocDiffbotDiscordDoclingDocugamiDocusaurusDropboxDuckDBEmailEPubEtherscanEverNoteexample_dataFacebook ChatFaunaFigmaFireCrawlGeopandasGitGitBookGitHubGlue CatalogGoogle AlloyDB for PostgreSQLGoogle BigQueryGoogle BigtableGoogle Cloud SQL for SQL serverGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLGoogle Cloud Storage DirectoryGoogle Cloud Storage FileGoogle Firestore in Datastore ModeGoogle DriveGoogle El Carro for Oracle WorkloadsGoogle Firestore (Native Mode)Google Memorystore for RedisGoogle SpannerGoogle Speech-to-Text Audio TranscriptsGrobidGutenbergHacker NewsHuawei OBS DirectoryHuawei OBS FileHuggingFace datasetHyperbrowserLoaderiFixitImagesImage captionsIMSDbIuguJoplinJSONLoaderJupyter NotebookKineticalakeFSLangSmithLarkSuite (FeiShu)LLM SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='SherpaMastodonMathPixPDFLoaderMediaWiki DumpMerge Documents LoadermhtmlMicrosoft ExcelMicrosoft OneDriveMicrosoft OneNoteMicrosoft PowerPointMicrosoft SharePointMicrosoft WordNear BlockchainModern TreasuryMongoDBNeedle Document LoaderNews URLNotion DB 2/2NucliaObsidianOpen Document Format (ODT)Open City DataOracle Autonomous DatabaseOracle AI Vector Search: Document ProcessingOrg-modePandas DataFrameparsersPDFMinerLoaderPDFPlumberPebblo Safe DocumentLoaderPolars DataFramePsychicPubMedPullMdLoaderPyMuPDFLoaderPyPDFDirectoryLoaderPyPDFium2LoaderPyPDFLoaderPySparkQuipReadTheDocs DocumentationRecursive URLRedditRoamRocksetrspaceRSS FeedsRSTscrapflyScrapingAntSitemapSlackSnowflakeSource CodeSpiderSpreedlyStripeSubtitleSurrealDBTelegramTencent COS DirectoryTencent COS FileTensorFlow DatasetsTiDB2MarkdownTOMLTrelloTSVTwitterUnstructuredUnstructuredMarkdownLoaderUnstructuredPDFLoaderUpstageURLVsdxWeatherWebBaseLoaderWhatsApp ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='ChatWikipediaUnstructuredXMLLoaderXorbits Pandas DataFrameYouTube audioYouTube transcriptsYoutubeLoaderDLYuqueZeroxPDFLoaderVector storesVector storesActiveloop Deep LakeAerospikeAlibaba Cloud OpenSearchAnalyticDBAnnoyApache DorisApertureDBAstra DB Vector StoreAtlasAwaDBAzure Cosmos DB Mongo vCoreAzure Cosmos DB No SQLAzure AI SearchBagelBagelDBBaidu Cloud ElasticSearch VectorSearchBaidu VectorDBApache CassandraChromaClarifaiClickHouseCouchbaseDashVectorDatabricksDingoDBDocArray HnswSearchDocArray InMemorySearchAmazon Document DBDuckDBChina Mobile ECloud ElasticSearch VectorSearchElasticsearchEpsillaFaissFaiss (Async)FalkorDBVectorStoreGoogle AlloyDB for PostgreSQLGoogle BigQuery Vector SearchGoogle Cloud SQL for MySQLGoogle Cloud SQL for PostgreSQLFirestoreGoogle Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content=\"Memorystore for RedisGoogle SpannerGoogle Vertex AI Feature StoreGoogle Vertex AI Vector SearchHippoHologresInfinispanJaguar Vector DatabaseKDB.AIKineticaLanceDBLanternLindormLLMRailsManticoreSearch VectorStoreMarqoMeilisearchAmazon MemoryDBMilvusMomento Vector Index (MVI)MongoDB AtlasMyScaleNeo4j Vector IndexNucliaDBOceanbaseOpenSearchOracle AI Vector Search: Vector StorePathwayPostgres EmbeddingPGVecto.rsPGVectorPineconeQdrantRedisRelytRocksetSAP HANA Cloud Vector EngineScaNNSemaDBSingleStoreDBscikit-learnSQLiteVecSQLite-VSSSQLServerStarRocksSupabase (Postgres)SurrealDBTablestoreTairTencent Cloud VectorDBThirdAI NeuralDBTiDB VectorTigrisTileDBTimescale Vector (Postgres)TypesenseUpstash VectorUSearchValdIntel's Visual Data Management System (VDMS)VearchVectaraVespaviking DBvliteWeaviateXataYellowbrickZepZep CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='CloudZillizEmbedding modelsEmbedding modelsAI21Aleph AlphaAnyscaleascendAwaDBAzureOpenAIBaichuan Text EmbeddingsBaidu QianfanBedrockBGE on Hugging FaceBookend AIClarifaiCloudflare Workers AIClova EmbeddingsCohereDashScopeDatabricksDeepInfraEDEN AIElasticsearchEmbaasERNIEFake EmbeddingsFastEmbed by QdrantFireworksGigaChatGoogle Generative AI EmbeddingsGoogle Vertex AIGPT4AllGradientHugging FaceIBM watsonx.aiInfinityInstruct Embeddings on Hugging FaceIPEX-LLM: Local BGE Embeddings on Intel CPUIPEX-LLM: Local BGE Embeddings on Intel GPUIntel¬Æ Extension for Transformers Quantized Text EmbeddingsJinaJohn Snow LabsLASER Language-Agnostic SEntence Representations Embeddings by Meta AILindormLlama.cppllamafileLLMRailsLocalAIMiniMaxMistralAImodel2vecModelScopeMosaicMLNaverNLP CloudNomicNVIDIA NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='NIMsOracle Cloud Infrastructure Generative AIOllamaOpenClipOpenAIOpenVINOEmbedding Documents using Optimized and Quantized EmbeddersOracle AI Vector Search: Generate EmbeddingsOVHcloudPinecone EmbeddingsPredictionGuardEmbeddingsPremAISageMakerSambaStudioSelf HostedSentence Transformers on Hugging FaceSolarSpaCySparkLLM Text EmbeddingsTensorFlow HubText Embeddings InferenceTextEmbed - Embedding Inference ServerTitan TakeoffTogether AIUpstageVolc EngineVoyage AIXorbits inference (Xinference)YandexGPTZhipuAIOtherComponentsDocument loadersWebBaseLoaderOn this pageWebBaseLoader'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content=\"This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.\\nIf you don't want to worry about website crawling, bypassing JS-blocking sites, and data cleaning, consider using FireCrawlLoader or the faster option SpiderLoader.\\nOverview\\u200b\\nIntegration details\\u200b\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='TODO: Fill in table features.\\nTODO: Remove JS support link if not relevant, otherwise ensure link is correct.\\nTODO: Make sure API reference links are correct.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='ClassPackageLocalSerializableJS supportWebBaseLoaderlangchain_community‚úÖ‚ùå‚ùå\\nLoader features\\u200b\\nSourceDocument Lazy LoadingNative Async SupportWebBaseLoader‚úÖ‚úÖ\\nSetup\\u200b\\nCredentials\\u200b\\nWebBaseLoader does not require any credentials.\\nInstallation\\u200b\\nTo use the WebBaseLoader you first need to install the langchain-community python package.\\n%pip install -qU langchain_community beautifulsoup4\\nInitialization\\u200b\\nNow we can instantiate our model object and load documents:\\nfrom langchain_community.document_loaders import WebBaseLoaderloader = WebBaseLoader(\"https://www.example.com/\")API Reference:WebBaseLoader\\nTo bypass SSL verification errors during fetching, you can set the \"verify\" option:\\nloader.requests_kwargs = {\\'verify\\':False}\\nInitialization with multiple pages\\u200b\\nYou can also pass in a list of pages to load from.\\nloader_multiple_pages = WebBaseLoader(    [\"https://www.example.com/\", \"https://google.com\"])\\nLoad\\u200b\\ndocs = loader.load()docs[0]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='You can also pass in a list of pages to load from.\\nloader_multiple_pages = WebBaseLoader(    [\"https://www.example.com/\", \"https://google.com\"])\\nLoad\\u200b\\ndocs = loader.load()docs[0]\\nDocument(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\')\\nprint(docs[0].metadata)\\n{\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}\\nLoad multiple urls concurrently\\u200b\\nYou can speed up the scraping process by scraping and parsing multiple urls concurrently.'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Load multiple urls concurrently\\u200b\\nYou can speed up the scraping process by scraping and parsing multiple urls concurrently.\\nThere are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren\\'t concerned about being a good citizen, or you control the server you are scraping and don\\'t care about load, you can change the requests_per_second parameter to increase the max concurrent requests.  Note, while this will speed up the scraping process, but may cause the server to block you.  Be careful!\\n%pip install -qU  nest_asyncio# fixes a bug with asyncio and jupyterimport nest_asyncionest_asyncio.apply()\\nNote: you may need to restart the kernel to use updated packages.\\nloader = WebBaseLoader([\"https://www.example.com/\", \"https://google.com\"])loader.requests_per_second = 1docs = loader.aload()docs\\nFetching pages: 100%|###########################################################################| 2/2 [00:00<00:00,  8.28it/s]'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='[Document(metadata={\\'source\\': \\'https://www.example.com/\\', \\'title\\': \\'Example Domain\\', \\'language\\': \\'No language found.\\'}, page_content=\\'\\\\n\\\\n\\\\nExample Domain\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nExample Domain\\\\nThis domain is for use in illustrative examples in documents. You may use this\\\\n    domain in literature without prior coordination or asking for permission.\\\\nMore information...\\\\n\\\\n\\\\n\\\\n\\'), Document(metadata={\\'source\\': \\'https://google.com\\', \\'title\\': \\'Google\\', \\'description\\': \"Search the world\\'s information, including webpages, images, videos and more. Google has many special features to help you find exactly what you\\'re looking for.\", \\'language\\': \\'en\\'}, page_content=\\'GoogleSearch Images Maps Play YouTube News Gmail Drive More ¬ªWeb History | Settings | Sign in\\\\xa0Advanced search5 ways Gemini can help during the HolidaysAdvertisingBusiness SolutionsAbout Google¬© 2024 - Privacy - Terms  \\')]\\nLoading a xml file, or using a different BeautifulSoup parser\\u200b'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Loading a xml file, or using a different BeautifulSoup parser\\u200b\\nYou can also look at SitemapLoader for an example of how to load a sitemap file, which is an example of using this feature.\\nloader = WebBaseLoader(    \"https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml\")loader.default_parser = \"xml\"docs = loader.load()docs'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content=\"[Document(metadata={'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}, page_content='\\\\n\\\\n10\\\\nEnergy\\\\n3\\\\n2018-01-01\\\\n2018-01-01\\\\nfalse\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n√Ç¬ß 431.86\\\\nSection √Ç¬ß 431.86\\\\n\\\\nEnergy\\\\nDEPARTMENT OF ENERGY\\\\nENERGY CONSERVATION\\\\nENERGY EFFICIENCY PROGRAM FOR CERTAIN COMMERCIAL AND INDUSTRIAL EQUIPMENT\\\\nCommercial Packaged Boilers\\\\nTest Procedures\\\\n\\\\n\\\\n\\\\n\\\\n¬ß\\\\u2009431.86\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n(a) Scope. This section provides test procedures, pursuant to the Energy Policy and Conservation Act (EPCA), as amended, which must be followed for measuring the combustion efficiency and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by conducting the appropriate test procedure(s) indicated in Table 1 of this section.\\\\n\\\\nTable 1‚ÄîTest Requirements for Commercial Packaged Boiler Equipment Classes\\\\n\\\\nEquipment category\\\\nSubcategory\\\\nCertified rated inputBtu/h\\\\n\\\\nStandards efficiency metric(¬ß\\\\u2009431.87)\\\\n\\\\nTest procedure(corresponding to\\\\nstandards efficiency\\\\nmetric required\\\\nby ¬ß\\\\u2009431.87)\\\\n\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nGas-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nHot Water\\\\nOil-fired\\\\n>2,500,000\\\\nCombustion Efficiency\\\\nAppendix A, Section 3.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nGas-fired (all*)\\\\n>2,500,000 and ‚â§5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3 with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\n‚â•300,000 and ‚â§2,500,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\nSteam\\\\nOil-fired\\\\n>2,500,000 and ‚â§5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.\\\\n\\\\n\\\\n\\\\u2003\\\\n\\\\n>5,000,000\\\\nThermal Efficiency\\\\nAppendix A, Section 2.OR\\\\nAppendix A, Section 3. with Section 2.4.3.2.\\\\n\\\\n\\\\n\\\\n*\\\\u2009Equipment classes for commercial packaged boilers as of July 22, 2009 (74 FR 36355) distinguish between gas-fired natural draft and all other gas-fired (except natural draft).\\\\n\\\\n(c) Field Tests. The field test provisions of appendix A may be'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content=\"as of July 22, 2009 (74 FR 36355) distinguish between gas-fired natural draft and all other gas-fired (except natural draft).\\\\n\\\\n(c) Field Tests. The field test provisions of appendix A may be used only to test a unit of commercial packaged boiler with rated input greater than 5,000,000 Btu/h.\\\\n[81 FR 89305, Dec. 9, 2016]\\\\n\\\\n\\\\nEnergy Efficiency Standards\\\\n\\\\n')]\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content=\"Lazy Load\\u200b\\nYou can use lazy loading to only load one page at a time in order to minimize memory requirements.\\npages = []for doc in loader.lazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\n10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}\\nAsync\\u200b\\npages = []async for doc in loader.alazy_load():    pages.append(doc)print(pages[0].page_content[:100])print(pages[0].metadata)\\nFetching pages: 100%|###########################################################################| 1/1 [00:00<00:00, 10.51it/s]``````output10Energy32018-01-012018-01-01falseUniform test method for the measurement of energy efficien{'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}\\nUsing proxies\\u200b\"),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Using proxies\\u200b\\nSometimes you might need to use proxies to get around IP blocks. You can pass in a dictionary of proxies to the loader (and requests underneath) to use them.\\nloader = WebBaseLoader(    \"https://www.walmart.com/search?q=parrots\",    proxies={        \"http\": \"http://{username}:{password}:@proxy.service.com:6666/\",        \"https\": \"https://{username}:{password}:@proxy.service.com:6666/\",    },)docs = loader.load()\\nAPI reference\\u200b\\nFor detailed documentation of all WebBaseLoader features and configurations head to the API reference: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.web_base.WebBaseLoader.html\\nRelated\\u200b'),\n",
       " Document(metadata={'source': 'https://python.langchain.com/docs/integrations/document_loaders/web_base/', 'title': 'WebBaseLoader | ü¶úÔ∏èüîó LangChain', 'description': 'This covers how to use WebBaseLoader to load all text from HTML webpages into a document format that we can use downstream. For more custom logic for loading webpages look at some child class examples such as IMSDbLoader, AZLyricsLoader, and CollegeConfidentialLoader.', 'language': 'en'}, page_content='Document loader conceptual guide\\nDocument loader how-to guides\\nEdit this pageWas this page helpful?PreviousWeatherNextWhatsApp ChatOverviewIntegration detailsLoader featuresSetupCredentialsInstallationInitializationInitialization with multiple pagesLoadLoad multiple urls concurrentlyLoading a xml file, or using a different BeautifulSoup parserLazy LoadAsyncUsing proxiesAPI referenceRelatedCommunityTwitterGitHubOrganizationPythonJS/TSMoreHomepageBlogYouTubeCopyright ¬© 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_chunks = text_splitter.split_documents(docs)\n",
    "text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Embedding\n",
    "Chunks -> Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/vy0rk_tj2fg2rhkts3qkxrq00000gp/T/ipykernel_87564/1022864893.py:2: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"gemma2:2b\") # Default -> Llama2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OllamaEmbeddings(base_url='http://localhost:11434', model='gemma2:2b', embed_instruction='passage: ', query_instruction='query: ', mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None, show_progress=False, headers=None, model_kwargs=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"gemma2:2b\") # Default -> Llama2\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x11644f410>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "faiss_db = FAISS.from_documents(documents=text_chunks, embedding=embeddings)\n",
    "faiss_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[Document(metadata={'source': 'https://www.govinfo.gov/content/pkg/CFR-2018-title10-vol3/xml/CFR-2018-title10-vol3-sec431-86.xml'}, page_content='\\\\n\\\\n10\\\\nEnergy\\\\n3\\\\n2018-01-01\\\\n2018-01-01\\\\nfalse\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n√Ç¬ß 431.86\\\\nSection √Ç¬ß 431.86\\\\n\\\\nEnergy\\\\nDEPARTMENT OF ENERGY\\\\nENERGY CONSERVATION\\\\nENERGY EFFICIENCY PROGRAM FOR CERTAIN COMMERCIAL AND INDUSTRIAL EQUIPMENT\\\\nCommercial Packaged Boilers\\\\nTest Procedures\\\\n\\\\n\\\\n\\\\n\\\\n¬ß\\\\u2009431.86\\\\nUniform test method for the measurement of energy efficiency of commercial packaged boilers.\\\\n(a) Scope. This section provides test procedures, pursuant to the Energy Policy and Conservation Act (EPCA), as amended, which must be followed for measuring the combustion efficiency and/or thermal efficiency of a gas- or oil-fired commercial packaged boiler.\\\\n(b) Testing and Calculations. Determine the thermal efficiency or combustion efficiency of commercial packaged boilers by\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"There are reasonable limits to concurrent request\"\n",
    "result = faiss_db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
