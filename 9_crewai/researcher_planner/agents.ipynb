{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()\n",
    "\n",
    "import os \n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Models \n",
    "llm = LLM(\n",
    "    model=\"groq/llama-3.3-70b-versatile\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = Agent(\n",
    "    role = \"Content Planner\",\n",
    "    goal=\"Plan engaging and factually accurate content on {topic}\",\n",
    "    backstory=\"You're working on planning a blog article \"\n",
    "              \"about the topic: {topic}.\"\n",
    "              \"You collect information that helps the \"\n",
    "              \"audience learn something \"\n",
    "              \"and make informed decisions. \"\n",
    "              \"Your work is the basis for \"\n",
    "              \"the Content Writer to write an article on this topic.\",\n",
    "    llm= llm,\n",
    "    allow_delegation=False,\n",
    "\tverbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = Agent(\n",
    "    role=\"Content Writer\",\n",
    "    goal=\"Write insightful and factually accurate \"\n",
    "         \"opinion piece about the topic: {topic}\",\n",
    "    backstory=\"You're working on a writing \"\n",
    "              \"a new opinion piece about the topic: {topic}. \"\n",
    "              \"You base your writing on the work of \"\n",
    "              \"the Content Planner, who provides an outline \"\n",
    "              \"and relevant context about the topic. \"\n",
    "              \"You follow the main objectives and \"\n",
    "              \"direction of the outline, \"\n",
    "              \"as provide by the Content Planner. \"\n",
    "              \"You also provide objective and impartial insights \"\n",
    "              \"and back them up with information \"\n",
    "              \"provide by the Content Planner. \"\n",
    "              \"You acknowledge in your opinion piece \"\n",
    "              \"when your statements are opinions \"\n",
    "              \"as opposed to objective statements.\",\n",
    "    llm= llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "editor = Agent(\n",
    "    role=\"Editor\",\n",
    "    goal=\"Edit a given blog post to align with \"\n",
    "         \"the writing style of the organization. \",\n",
    "    backstory=\"You are an editor who receives a blog post \"\n",
    "              \"from the Content Writer. \"\n",
    "              \"Your goal is to review the blog post \"\n",
    "              \"to ensure that it follows journalistic best practices,\"\n",
    "              \"provides balanced viewpoints \"\n",
    "              \"when providing opinions or assertions, \"\n",
    "              \"and also avoids major controversial topics \"\n",
    "              \"or opinions when possible.\",\n",
    "    llm=llm,\n",
    "    allow_delegation=False,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = Task(\n",
    "    description=(\n",
    "        \"1. Prioritize the latest trends, key players, \"\n",
    "            \"and noteworthy news on {topic}.\\n\"\n",
    "        \"2. Identify the target audience, considering \"\n",
    "            \"their interests and pain points.\\n\"\n",
    "        \"3. Develop a detailed content outline including \"\n",
    "            \"an introduction, key points, and a call to action.\\n\"\n",
    "        \"4. Include SEO keywords and relevant data or sources.\"\n",
    "    ),\n",
    "    expected_output=\"A comprehensive content plan document \"\n",
    "        \"with an outline, audience analysis, \"\n",
    "        \"SEO keywords, and resources.\",\n",
    "    agent=planner,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "write = Task(\n",
    "    description=(\n",
    "        \"1. Use the content plan to craft a compelling \"\n",
    "            \"blog post on {topic}.\\n\"\n",
    "        \"2. Incorporate SEO keywords naturally.\\n\"\n",
    "\t\t\"3. Sections/Subtitles are properly named \"\n",
    "            \"in an engaging manner.\\n\"\n",
    "        \"4. Ensure the post is structured with an \"\n",
    "            \"engaging introduction, insightful body, \"\n",
    "            \"and a summarizing conclusion.\\n\"\n",
    "        \"5. Proofread for grammatical errors and \"\n",
    "            \"alignment with the brand's voice.\\n\"\n",
    "    ),\n",
    "    expected_output=\"A well-written blog post \"\n",
    "        \"in markdown format, ready for publication, \"\n",
    "        \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=writer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit = Task(\n",
    "    description=(\"Proofread the given blog post for \"\n",
    "                 \"grammatical errors and \"\n",
    "                 \"alignment with the brand's voice.\"),\n",
    "    expected_output=\"A well-written blog post in markdown format, \"\n",
    "                    \"ready for publication, \"\n",
    "                    \"each section should have 2 or 3 paragraphs.\",\n",
    "    agent=editor\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "## Crew operates Sequentially\n",
    "crew = Crew(\n",
    "    agents=[planner, writer, editor],\n",
    "    tasks=[plan, write, edit],\n",
    "    # verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Prioritize the latest trends, key players, and noteworthy news on Artificial Intelligence.\n",
      "2. Identify the target audience, considering their interests and pain points.\n",
      "3. Develop a detailed content outline including an introduction, key points, and a call to action.\n",
      "4. Include SEO keywords and relevant data or sources.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Planner\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "**Comprehensive Content Plan Document: Artificial Intelligence**\n",
      "\n",
      "**I. Introduction**\n",
      "\n",
      "The purpose of this content plan is to create an informative and engaging article about Artificial Intelligence (AI) that caters to the interests and pain points of the target audience. The article aims to provide an overview of the latest trends, key players, and noteworthy news in the AI industry, while also offering practical insights and a call to action.\n",
      "\n",
      "**II. Target Audience Analysis**\n",
      "\n",
      "The target audience for this article includes:\n",
      "\n",
      "* **Demographics:** Professionals, entrepreneurs, and individuals interested in technology and innovation, aged 25-50.\n",
      "* **Interests:** Staying updated on the latest technological advancements, understanding the impact of AI on business and society, and exploring potential applications and opportunities.\n",
      "* **Pain Points:** Limited knowledge about AI, difficulty in understanding its relevance and potential applications, and concerns about job displacement and ethics.\n",
      "* **Goals:** To gain a deeper understanding of AI, its current state, and future prospects, as well as to identify potential opportunities and challenges.\n",
      "\n",
      "**III. Detailed Content Outline**\n",
      "\n",
      "1. **Introduction to Artificial Intelligence**\n",
      "\t* Definition and explanation of AI\n",
      "\t* Brief history and evolution of AI\n",
      "\t* Current state of AI and its applications\n",
      "2. **Latest Trends in Artificial Intelligence**\n",
      "\t* Machine Learning (ML) and Deep Learning (DL)\n",
      "\t* Natural Language Processing (NLP) and Computer Vision\n",
      "\t* Edge AI and IoT\n",
      "3. **Key Players in the AI Industry**\n",
      "\t* Tech giants: Google, Amazon, Microsoft, Facebook\n",
      "\t* AI startups and innovators\n",
      "\t* Research institutions and academia\n",
      "4. **Noteworthy News and Developments**\n",
      "\t* Recent breakthroughs and achievements in AI research\n",
      "\t* AI-related news and updates from the tech industry\n",
      "\t* Government initiatives and regulations related to AI\n",
      "5. **Practical Applications and Opportunities**\n",
      "\t* AI in business: marketing, customer service, and automation\n",
      "\t* AI in healthcare: diagnosis, treatment, and patient care\n",
      "\t* AI in education: personalized learning and accessibility\n",
      "6. **Challenges and Concerns**\n",
      "\t* Job displacement and workforce transformation\n",
      "\t* Ethics and bias in AI decision-making\n",
      "\t* Cybersecurity and data protection\n",
      "7. **Call to Action**\n",
      "\t* Encouragement to explore AI-related resources and courses\n",
      "\t* Invitation to join online communities and forums\n",
      "\t* Recommendation to attend AI-related events and conferences\n",
      "\n",
      "**IV. SEO Keywords and Relevant Data**\n",
      "\n",
      "* Primary keywords: Artificial Intelligence, Machine Learning, Natural Language Processing, Computer Vision\n",
      "* Secondary keywords: AI applications, AI trends, AI industry, AI research\n",
      "* Relevant data and statistics:\n",
      "\t+ AI market size and growth projections\n",
      "\t+ Adoption rates of AI in various industries\n",
      "\t+ Number of AI-related jobs and career opportunities\n",
      "* Sources:\n",
      "\t+ Research reports from Gartner, McKinsey, and Forrester\n",
      "\t+ Articles and publications from The New York Times, Forbes, and WIRED\n",
      "\t+ Data and statistics from Statista, Google Trends, and LinkedIn\n",
      "\n",
      "**V. Resources**\n",
      "\n",
      "* **Books:**\n",
      "\t+ \"Life 3.0: Being Human in the Age of Artificial Intelligence\" by Max Tegmark\n",
      "\t+ \"The Singularity Is Near: When Humans Transcend Biology\" by Ray Kurzweil\n",
      "* **Online Courses:**\n",
      "\t+ Andrew Ng's Machine Learning course on Coursera\n",
      "\t+ Stanford University's Natural Language Processing with Deep Learning Specialization\n",
      "* **Websites and Blogs:**\n",
      "\t+ AI Alignment Forum\n",
      "\t+ Machine Learning Mastery\n",
      "\t+ KDnuggets\n",
      "* **Conferences and Events:**\n",
      "\t+ NeurIPS (Conference on Neural Information Processing Systems)\n",
      "\t+ IJCAI (International Joint Conference on Artificial Intelligence)\n",
      "\t+ AI Summit\n",
      "\n",
      "By following this comprehensive content plan, the article will provide a thorough and engaging overview of Artificial Intelligence, catering to the interests and pain points of the target audience, while also incorporating relevant SEO keywords and data.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92m1. Use the content plan to craft a compelling blog post on Artificial Intelligence.\n",
      "2. Incorporate SEO keywords naturally.\n",
      "3. Sections/Subtitles are properly named in an engaging manner.\n",
      "4. Ensure the post is structured with an engaging introduction, insightful body, and a summarizing conclusion.\n",
      "5. Proofread for grammatical errors and alignment with the brand's voice.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mContent Writer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "### Introduction to Artificial Intelligence\n",
      "Artificial Intelligence (AI) has become a buzzword in the tech industry, with its applications and potential uses being explored in various sectors. But what exactly is Artificial Intelligence? In simple terms, AI refers to the development of computer systems that can perform tasks that would typically require human intelligence, such as learning, problem-solving, and decision-making. The history of AI dates back to the 1950s, when computer scientists like Alan Turing and Marvin Minsky began exploring the possibilities of creating intelligent machines. Since then, AI has evolved significantly, with the current state of AI being characterized by the use of Machine Learning (ML) and Deep Learning (DL) algorithms to enable computers to learn from data and improve their performance over time.\n",
      "\n",
      "The current state of AI is marked by its increasing presence in our daily lives, from virtual assistants like Siri and Alexa to self-driving cars and personalized product recommendations. However, despite its growing popularity, many people still have limited knowledge about AI and its potential applications. This is where our article comes in – to provide an overview of the latest trends, key players, and noteworthy news in the AI industry, while also offering practical insights and a call to action. Whether you're a professional looking to stay updated on the latest technological advancements or an individual interested in exploring the possibilities of AI, this article aims to cater to your interests and pain points.\n",
      "\n",
      "As we delve into the world of Artificial Intelligence, it's essential to understand the relevance and potential applications of AI in various industries. From healthcare and education to marketing and customer service, AI is transforming the way we live and work. In this article, we'll explore the latest trends in AI, including Machine Learning, Natural Language Processing, and Edge AI, and examine the key players in the AI industry, including tech giants, startups, and research institutions. We'll also discuss the challenges and concerns surrounding AI, such as job displacement and ethics, and provide a call to action for those interested in exploring AI-related resources and courses.\n",
      "\n",
      "### Latest Trends in Artificial Intelligence\n",
      "The field of Artificial Intelligence is constantly evolving, with new trends and breakthroughs emerging regularly. One of the most significant trends in AI is the use of Machine Learning (ML) and Deep Learning (DL) algorithms to enable computers to learn from data and improve their performance over time. ML and DL have numerous applications, including image and speech recognition, natural language processing, and predictive analytics. Another trend in AI is the use of Natural Language Processing (NLP) and Computer Vision to enable computers to understand and interpret human language and visual data. NLP has numerous applications, including chatbots, virtual assistants, and language translation, while Computer Vision has applications in areas such as self-driving cars, surveillance, and medical imaging.\n",
      "\n",
      "Edge AI is another trend that's gaining traction, as it enables AI algorithms to run on edge devices, such as smartphones, smart home devices, and autonomous vehicles. This reduces the need for cloud connectivity and enables faster and more efficient processing of data. The Internet of Things (IoT) is also driving the adoption of AI, as it generates vast amounts of data that can be used to train AI models. According to a report by Gartner, the number of IoT devices is expected to reach 20.4 billion by 2025, driving the need for AI-powered analytics and decision-making. As AI continues to evolve, we can expect to see new trends and breakthroughs emerge, transforming the way we live and work.\n",
      "\n",
      "The latest trends in AI are not only driven by technological advancements but also by the increasing demand for AI-powered solutions. According to a report by McKinsey, the AI market is expected to reach $190 billion by 2025, with the majority of the growth coming from the adoption of AI in industries such as healthcare, finance, and retail. As AI becomes more pervasive, it's essential to understand the potential applications and challenges of AI and to explore the various resources and courses available for those interested in pursuing a career in AI.\n",
      "\n",
      "### Key Players in the AI Industry\n",
      "The AI industry is characterized by the presence of various key players, including tech giants, startups, and research institutions. Tech giants like Google, Amazon, Microsoft, and Facebook are investing heavily in AI research and development, with a focus on applications such as virtual assistants, image recognition, and natural language processing. These companies are also acquiring AI startups and talent to enhance their AI capabilities. Startups, on the other hand, are driving innovation in AI, with many focusing on specific applications such as chatbots, predictive analytics, and computer vision.\n",
      "\n",
      "Research institutions and academia are also playing a crucial role in the development of AI, with many universities and research centers conducting cutting-edge research in areas such as ML, DL, and NLP. These institutions are also collaborating with industry partners to develop AI-powered solutions and to provide training and education in AI. According to a report by Forrester, the number of AI-related research papers published in 2020 increased by 20% compared to the previous year, indicating the growing interest in AI research. As the AI industry continues to evolve, we can expect to see new key players emerge, driving innovation and adoption of AI.\n",
      "\n",
      "The key players in the AI industry are not only driving innovation but also creating new opportunities for those interested in pursuing a career in AI. According to a report by LinkedIn, the demand for AI professionals is expected to increase by 34% in the next five years, with the majority of the demand coming from industries such as healthcare, finance, and technology. As the AI industry continues to grow, it's essential to understand the various resources and courses available for those interested in pursuing a career in AI, including online courses, books, and conferences.\n",
      "\n",
      "### Noteworthy News and Developments\n",
      "The AI industry is constantly evolving, with new breakthroughs and developments emerging regularly. One of the most significant recent breakthroughs in AI is the development of AlphaFold, a AI-powered system that can predict the 3D structure of proteins. This breakthrough has the potential to revolutionize the field of biology and medicine, enabling the development of new treatments and therapies. Another notable development in AI is the use of AI-powered systems to detect and diagnose diseases, such as cancer and diabetes.\n",
      "\n",
      "The AI industry is also witnessing significant investments, with many companies and governments investing heavily in AI research and development. According to a report by Statista, the global AI market is expected to reach $190 billion by 2025, with the majority of the growth coming from the adoption of AI in industries such as healthcare, finance, and retail. The government is also playing a crucial role in the development of AI, with many countries investing in AI research and development and implementing regulations to ensure the safe and responsible use of AI. As the AI industry continues to evolve, we can expect to see new breakthroughs and developments emerge, transforming the way we live and work.\n",
      "\n",
      "The noteworthy news and developments in the AI industry are not only driven by technological advancements but also by the increasing demand for AI-powered solutions. According to a report by Gartner, the number of companies adopting AI is expected to increase by 25% in the next two years, with the majority of the adoption coming from industries such as healthcare, finance, and retail. As AI becomes more pervasive, it's essential to understand the potential applications and challenges of AI and to explore the various resources and courses available for those interested in pursuing a career in AI.\n",
      "\n",
      "### Practical Applications and Opportunities\n",
      "Artificial Intelligence has numerous practical applications and opportunities, transforming the way we live and work. One of the most significant applications of AI is in the field of healthcare, where AI-powered systems can be used to diagnose and treat diseases, such as cancer and diabetes. AI can also be used to personalize medicine, enabling doctors to tailor treatments to individual patients. In the field of education, AI can be used to create personalized learning plans, enabling students to learn at their own pace and improving student outcomes.\n",
      "\n",
      "AI also has numerous applications in business, including marketing, customer service, and automation. AI-powered chatbots can be used to provide customer support, while AI-powered systems can be used to automate tasks such as data entry and bookkeeping. According to a report by McKinsey, the adoption of AI in business can increase productivity by up to 40%, enabling companies to reduce costs and improve efficiency. As AI continues to evolve, we can expect to see new applications and opportunities emerge, transforming the way we live and work.\n",
      "\n",
      "The practical applications and opportunities of AI are not only driven by technological advancements but also by the increasing demand for AI-powered solutions. According to a report by Forrester, the number of companies adopting AI is expected to increase by 25% in the next two years, with the majority of the adoption coming from industries such as healthcare, finance, and retail. As AI becomes more pervasive, it's essential to understand the potential applications and challenges of AI and to explore the various resources and courses available for those interested in pursuing a career in AI.\n",
      "\n",
      "### Challenges and Concerns\n",
      "While Artificial Intelligence has numerous benefits and opportunities, it also raises several challenges and concerns. One of the most significant challenges of AI is the potential for job displacement, as AI-powered systems automate tasks and jobs. According to a report by the McKinsey Global Institute, up to 800 million jobs could be lost worldwide due to automation by 2030. Another challenge of AI is the potential for bias and discrimination, as AI systems can perpetuate existing biases and prejudices.\n",
      "\n",
      "Cybersecurity is also a significant concern, as AI-powered systems can be vulnerable to cyber attacks and data breaches. According to a report by Cybersecurity Ventures, the global cost of cybercrime is expected to reach $6 trillion by 2023, with the majority of the cost coming from data breaches and cyber attacks. As AI becomes more pervasive, it's essential to address these challenges and concerns, ensuring that AI is developed and used in a safe and responsible manner.\n",
      "\n",
      "The challenges and concerns surrounding AI are not only driven by technological advancements but also by the increasing demand for AI-powered solutions. According to a report by Gartner, the number of companies adopting AI is expected to increase by 25% in the next two years, with the majority of the adoption coming from industries such as healthcare, finance, and retail. As AI becomes more pervasive, it's essential to understand the potential applications and challenges of AI and to explore the various resources and courses available for those interested in pursuing a career in AI.\n",
      "\n",
      "### Conclusion\n",
      "In conclusion, Artificial Intelligence is a rapidly evolving field with numerous applications and opportunities. From healthcare and education to business and marketing, AI is transforming the way we live and work. However, AI also raises several challenges and concerns, including job displacement, bias and discrimination, and cybersecurity. As AI becomes more pervasive, it's essential to address these challenges and concerns, ensuring that AI is developed and used in a safe and responsible manner.\n",
      "\n",
      "For those interested in pursuing a career in AI, there are numerous resources and courses available, including online courses, books, and conferences. According to a report by LinkedIn, the demand for AI professionals is expected to increase by 34% in the next five years, with the majority of the demand coming from industries such as healthcare, finance, and technology. As the AI industry continues to grow, it's essential to stay updated on the latest trends and breakthroughs, and to explore the various opportunities and challenges of AI.\n",
      "\n",
      "In the end, the future of Artificial Intelligence is exciting and uncertain, with numerous possibilities and challenges emerging. As we continue to develop and use AI, it's essential to prioritize safety, responsibility, and ethics, ensuring that AI is used to benefit humanity and improve the world. Whether you're a professional, entrepreneur, or individual, AI is an exciting and rapidly evolving field that's worth exploring and understanding. By staying informed and up-to-date on the latest trends and breakthroughs in AI, you can unlock new opportunities and possibilities, and contribute to the development of a safer, more responsible, and more beneficial AI future.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mEditor\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mProofread the given blog post for grammatical errors and alignment with the brand's voice.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:LiteLLM call failed: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1y745vvead8k6217mcxsdc1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3777, Requested 4629. Please try again in 24.057s. Visit https://console.groq.com/docs/rate-limits for more information.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\u001b[91m Error during LLM call: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1y745vvead8k6217mcxsdc1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3777, Requested 4629. Please try again in 24.057s. Visit https://console.groq.com/docs/rate-limits for more information.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\u001b[00m\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1y745vvead8k6217mcxsdc1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3777, Requested 4629. Please try again in 24.057s. Visit https://console.groq.com/docs/rate-limits for more information.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/llms/openai_like/chat/handler.py:372\u001b[0m, in \u001b[0;36mOpenAILikeChatHandler.completion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:553\u001b[0m, in \u001b[0;36mHTTPHandler.post\u001b[0;34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code)\n\u001b[0;32m--> 553\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/llms/custom_httpx/http_handler.py:534\u001b[0m, in \u001b[0;36mHTTPHandler.post\u001b[0;34m(self, url, data, json, params, headers, stream, timeout, files, content, logging_obj)\u001b[0m\n\u001b[1;32m    533\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39msend(req, stream\u001b[38;5;241m=\u001b[39mstream)\n\u001b[0;32m--> 534\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/httpx/_models.py:763\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 763\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '429 Too Many Requests' for url 'https://api.groq.com/openai/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOpenAILikeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/main.py:1549\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   1547\u001b[0m             optional_params[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m-> 1549\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_chat_completions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m custom_llm_provider \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maiohttp_openai\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1569\u001b[0m     \u001b[38;5;66;03m# NEW aiohttp provider for 10-100x higher RPS\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/llms/groq/chat/handler.py:55\u001b[0m, in \u001b[0;36mGroqChatCompletion.completion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m     53\u001b[0m     fake_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43macompletion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_endpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstreaming_decoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreaming_decoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfake_stream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfake_stream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/llms/openai_like/chat/handler.py:378\u001b[0m, in \u001b[0;36mOpenAILikeChatHandler.completion\u001b[0;34m(self, model, messages, api_base, custom_llm_provider, custom_prompt_dict, model_response, print_verbose, encoding, api_key, logging_obj, optional_params, acompletion, litellm_params, logger_fn, headers, timeout, client, custom_endpoint, streaming_decoder, fake_stream)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 378\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAILikeError(\n\u001b[1;32m    379\u001b[0m         status_code\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[1;32m    380\u001b[0m         message\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException:\n",
      "\u001b[0;31mOpenAILikeError\u001b[0m: {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1y745vvead8k6217mcxsdc1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3777, Requested 4629. Please try again in 24.057s. Visit https://console.groq.com/docs/rate-limits for more information.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcrew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkickoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtopic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mArtificial Intelligence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/crew.py:576\u001b[0m, in \u001b[0;36mCrew.kickoff\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    573\u001b[0m metrics: List[UsageMetrics] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39msequential:\n\u001b[0;32m--> 576\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sequential_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m==\u001b[39m Process\u001b[38;5;241m.\u001b[39mhierarchical:\n\u001b[1;32m    578\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_hierarchical_process()\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/crew.py:683\u001b[0m, in \u001b[0;36mCrew._run_sequential_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_sequential_process\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CrewOutput:\n\u001b[1;32m    682\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes tasks sequentially and returns the final output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_tasks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/crew.py:781\u001b[0m, in \u001b[0;36mCrew._execute_tasks\u001b[0;34m(self, tasks, start_index, was_replayed)\u001b[0m\n\u001b[1;32m    778\u001b[0m     futures\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    780\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_context(task, task_outputs)\n\u001b[0;32m--> 781\u001b[0m task_output \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent_to_use\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools_for_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m task_outputs\u001b[38;5;241m.\u001b[39mappend(task_output)\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_task_result(task, task_output)\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/task.py:302\u001b[0m, in \u001b[0;36mTask.execute_sync\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute_sync\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    297\u001b[0m     agent: Optional[BaseAgent] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    298\u001b[0m     context: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m     tools: Optional[List[BaseTool]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    300\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskOutput:\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task synchronously.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/task.py:366\u001b[0m, in \u001b[0;36mTask._execute_core\u001b[0;34m(self, agent, context, tools)\u001b[0m\n\u001b[1;32m    362\u001b[0m tools \u001b[38;5;241m=\u001b[39m tools \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_by_agents\u001b[38;5;241m.\u001b[39madd(agent\u001b[38;5;241m.\u001b[39mrole)\n\u001b[0;32m--> 366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m pydantic_output, json_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_export_output(result)\n\u001b[1;32m    373\u001b[0m task_output \u001b[38;5;241m=\u001b[39m TaskOutput(\n\u001b[1;32m    374\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    375\u001b[0m     description\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescription,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m     output_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_output_format(),\n\u001b[1;32m    382\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agent.py:254\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 254\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_times_executed \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retry_limit:\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agent.py:243\u001b[0m, in \u001b[0;36mAgent.execute_task\u001b[0;34m(self, task, context, tools)\u001b[0m\n\u001b[1;32m    240\u001b[0m     task_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_trained_data(task_prompt\u001b[38;5;241m=\u001b[39mtask_prompt)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_names\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtools_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mask_for_human_input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhuman_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:112\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_unknown_error(e)\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:102\u001b[0m, in \u001b[0;36mCrewAgentExecutor.invoke\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mask_for_human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mask_for_human_input\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    105\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent failed to reach a final answer. This is likely a bug - please report it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    106\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    107\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:160\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Do not retry on litellm errors\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_context_length_exceeded(e):\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_context_length()\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:140\u001b[0m, in \u001b[0;36mCrewAgentExecutor._invoke_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enforce_rpm_limit()\n\u001b[0;32m--> 140\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_llm_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m formatted_answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_llm_response(answer)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_answer, AgentAction):\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:210\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    207\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m answer:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    214\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived None or empty response from LLM call.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    215\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    216\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/agents/crew_agent_executor.py:201\u001b[0m, in \u001b[0;36mCrewAgentExecutor._get_llm_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call the LLM and return the response, handling any invalid responses.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_printer\u001b[38;5;241m.\u001b[39mprint(\n\u001b[1;32m    207\u001b[0m         content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during LLM call: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m         color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/crewai/llm.py:291\u001b[0m, in \u001b[0;36mLLM.call\u001b[0;34m(self, messages, tools, callbacks, available_functions)\u001b[0m\n\u001b[1;32m    288\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# --- 2) Make the completion call\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlitellm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m response_message \u001b[38;5;241m=\u001b[39m cast(Choices, cast(ModelResponse, response)\u001b[38;5;241m.\u001b[39mchoices)[\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    294\u001b[0m ]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[1;32m    295\u001b[0m text_response \u001b[38;5;241m=\u001b[39m response_message\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/utils.py:1154\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[1;32m   1151\u001b[0m     logging_obj\u001b[38;5;241m.\u001b[39mfailure_handler(\n\u001b[1;32m   1152\u001b[0m         e, traceback_exception, start_time, end_time\n\u001b[1;32m   1153\u001b[0m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/utils.py:1032\u001b[0m, in \u001b[0;36mclient.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         print_verbose(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/main.py:3068\u001b[0m, in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, deployment_id, extra_headers, functions, function_call, base_url, api_version, api_key, model_list, **kwargs)\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m   3066\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   3067\u001b[0m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[0;32m-> 3068\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3069\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3070\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3072\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3073\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3074\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2201\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[1;32m   2200\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlitellm_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, litellm_response_headers)\n\u001b[0;32m-> 2201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm\u001b[38;5;241m.\u001b[39mLITELLM_EXCEPTION_TYPES:\n",
      "File \u001b[0;32m~/Documents/multi-agents/langchain-learning/llvenv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:425\u001b[0m, in \u001b[0;36mexception_type\u001b[0;34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m429\u001b[39m:\n\u001b[1;32m    424\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RateLimitError(\n\u001b[1;32m    426\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRateLimitError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    427\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    428\u001b[0m         llm_provider\u001b[38;5;241m=\u001b[39mcustom_llm_provider,\n\u001b[1;32m    429\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    430\u001b[0m         litellm_debug_info\u001b[38;5;241m=\u001b[39mextra_information,\n\u001b[1;32m    431\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m original_exception\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m503\u001b[39m:\n\u001b[1;32m    433\u001b[0m     exception_mapping_worked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRateLimitError\u001b[0m: litellm.RateLimitError: RateLimitError: GroqException - {\"error\":{\"message\":\"Rate limit reached for model `llama-3.3-70b-versatile` in organization `org_01j1y745vvead8k6217mcxsdc1` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Used 3777, Requested 4629. Please try again in 24.057s. Visit https://console.groq.com/docs/rate-limits for more information.\",\"type\":\"tokens\",\"code\":\"rate_limit_exceeded\"}}\n"
     ]
    }
   ],
   "source": [
    "result = crew.kickoff(inputs={\"topic\": \"Artificial Intelligence\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
